{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip uninstall transformers -y\n!pip install --upgrade --no-cache-dir -q transformers==4.52.1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T14:40:40.400971Z","iopub.execute_input":"2025-10-15T14:40:40.401222Z","iopub.status.idle":"2025-10-15T14:40:55.709025Z","shell.execute_reply.started":"2025-10-15T14:40:40.401195Z","shell.execute_reply":"2025-10-15T14:40:55.70825Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import transformers\nfrom transformers import AutoProcessor, AutoModelForCausalLM  \nfrom PIL import Image\nimport requests\nimport copy\n%matplotlib inline  \nprint(transformers.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T14:40:55.709938Z","iopub.execute_input":"2025-10-15T14:40:55.710141Z","iopub.status.idle":"2025-10-15T14:41:19.760085Z","shell.execute_reply.started":"2025-10-15T14:40:55.710122Z","shell.execute_reply":"2025-10-15T14:41:19.759477Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import gc\nllm_model=None\nvision_processor=None\nvision_model=None\nllm_tokenizer=None\ngc.collect()\ntorch.cuda.empty_cache()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T14:27:10.996572Z","iopub.execute_input":"2025-10-15T14:27:10.996895Z","iopub.status.idle":"2025-10-15T14:27:11.406042Z","shell.execute_reply.started":"2025-10-15T14:27:10.99687Z","shell.execute_reply":"2025-10-15T14:27:11.405039Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_id = 'microsoft/Florence-2-large-ft'\nvision_model = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True, revision=\"main\", torch_dtype='auto').eval().cuda()\nvision_processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True, revision=\"main\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T14:42:51.305778Z","iopub.execute_input":"2025-10-15T14:42:51.306494Z","iopub.status.idle":"2025-10-15T14:43:05.10548Z","shell.execute_reply.started":"2025-10-15T14:42:51.306464Z","shell.execute_reply":"2025-10-15T14:43:05.104642Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"help(vision_model.generate)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Блок генерации Bearth признаков\n# главное это encoder_hidden_states[-1]","metadata":{}},{"cell_type":"code","source":"import torch\n\nurl = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/car.jpg?download=true\"\nimage = Image.open(requests.get(url, stream=True).raw)\ntask_prompts = [  \n    'Describe in detail what is shown in the image.',  \n    'What is the text in the image?',  \n    'Locate the objects in the image, with their descriptions.'  \n]  \n  \n   \nimages = [image] * 3   \ninputs = vision_processor(text=task_prompts, images=images, return_tensors=\"pt\", padding=True).to('cuda', torch.float16)\n   \ngenerated_ids = vision_model.generate(\n      input_ids=inputs[\"input_ids\"].cuda(),\n      pixel_values=inputs[\"pixel_values\"].cuda(),\n      max_new_tokens=1024,\n      early_stopping=False,\n      do_sample=False,\n      return_dict_in_generate=True,\n      output_hidden_states=True,\n      num_beams=3,\n    )\n\nlast_hidden_state = generated_ids.encoder_hidden_states[-1]\nprint(last_hidden_state.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T14:53:01.001777Z","iopub.execute_input":"2025-10-15T14:53:01.002091Z","iopub.status.idle":"2025-10-15T14:53:02.380843Z","shell.execute_reply.started":"2025-10-15T14:53:01.002058Z","shell.execute_reply":"2025-10-15T14:53:02.379955Z"},"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/car.jpg?download=true\"\nimage = Image.open(requests.get(url, stream=True).raw)\ntask_prompt = '<CAPTION>'\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T12:05:53.840239Z","iopub.execute_input":"2025-10-15T12:05:53.840827Z","iopub.status.idle":"2025-10-15T12:05:54.133973Z","shell.execute_reply.started":"2025-10-15T12:05:53.840802Z","shell.execute_reply":"2025-10-15T12:05:54.133241Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":" vision_model.vision_tower","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T11:37:52.146361Z","iopub.execute_input":"2025-10-15T11:37:52.146956Z","iopub.status.idle":"2025-10-15T11:37:52.155872Z","shell.execute_reply.started":"2025-10-15T11:37:52.146933Z","shell.execute_reply":"2025-10-15T11:37:52.155186Z"},"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(dir(vision_model.vision_tower))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T11:51:40.458276Z","iopub.execute_input":"2025-10-15T11:51:40.458569Z","iopub.status.idle":"2025-10-15T11:51:40.46297Z","shell.execute_reply.started":"2025-10-15T11:51:40.458548Z","shell.execute_reply":"2025-10-15T11:51:40.462253Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Блок генерации Depth признаков\n# главное это vision_model.vision_tower.forward_features_unpool","metadata":{}},{"cell_type":"code","source":"\nurl = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/car.jpg?download=true\"\nimage = Image.open(requests.get(url, stream=True).raw)\ntask_prompts = [  \n    'Describe in detail what is shown in the image.',  \n    'What is the text in the image?',  \n    'Locate the objects in the image, with their descriptions.'  \n]  \n  \n   \n     \ninputs = vision_processor(text=task_prompts, images=image, return_tensors=\"pt\", padding=True)    \n        \ninputs[\"input_ids\"] = inputs[\"input_ids\"].to('cuda')    \ninputs[\"pixel_values\"] = inputs[\"pixel_values\"].to('cuda', dtype=torch.float16)   ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T14:56:41.211053Z","iopub.execute_input":"2025-10-15T14:56:41.211675Z","iopub.status.idle":"2025-10-15T14:56:41.503161Z","shell.execute_reply.started":"2025-10-15T14:56:41.211652Z","shell.execute_reply":"2025-10-15T14:56:41.502342Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nwith torch.no_grad():\n    image_features = vision_model.vision_tower.forward_features_unpool(inputs[\"pixel_values\"])\nprint(image_features.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T14:56:44.069044Z","iopub.execute_input":"2025-10-15T14:56:44.06961Z","iopub.status.idle":"2025-10-15T14:56:44.099136Z","shell.execute_reply.started":"2025-10-15T14:56:44.069586Z","shell.execute_reply":"2025-10-15T14:56:44.098578Z"}},"outputs":[],"execution_count":null}]}