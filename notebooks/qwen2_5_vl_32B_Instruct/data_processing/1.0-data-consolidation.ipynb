{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\nfrom io import BytesIO\nfrom typing import Any, Dict, List, Tuple, Union\n\nimport pandas as pd\nfrom datasets import load_dataset\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\n\n\n# Helpers\n\ndef _to_pil_image(image_data: Any) -> Union[Image.Image, None]:\n    \"\"\"\n    Преобразует данные изображения в объект PIL.Image. \n    Возвращает None для некорректных/пустых данных.\n    \"\"\"\n    if image_data is None:\n        return None\n        \n    try:\n        if isinstance(image_data, Image.Image):\n            return image_data\n        elif isinstance(image_data, bytes):\n            return Image.open(BytesIO(image_data))\n        # Если в датасете есть поле \"bytes\" внутри словаря (как в ruVQA)\n        elif isinstance(image_data, dict) and \"bytes\" in image_data and isinstance(image_data[\"bytes\"], bytes):\n            return Image.open(BytesIO(image_data[\"bytes\"]))\n    except Exception as e:\n        print(f\"Не удалось открыть изображение: {e}\")\n        return None\n        \n    return None\n    \ndef _split_dataset(entries: List[Dict[str, Any]],\n                   split_ratio: Tuple[float, float, float]) -> Dict[str, List[Dict[str, Any]]]:\n    train_ratio, val_ratio, test_ratio = split_ratio\n    train_val_ratio = train_ratio + val_ratio\n    \n    # Чтобы избежать ошибки при пустом списке\n    if not entries:\n        return {\"train\": [], \"val\": [], \"test\": []}\n\n    train_val, test = train_test_split(entries, test_size=test_ratio, random_state=42)\n    \n    # Проверка, что train_val не пуст перед вторым разделением\n    if not train_val:\n        return {\"train\": [], \"val\": [], \"test\": test}\n        \n    train, val = train_test_split(train_val, test_size=val_ratio / train_val_ratio, random_state=42)\n\n    return {\"train\": train, \"val\": val, \"test\": test}\n    \n# Loaders\n\ndef load_docmatix_limited(\n    max_final_samples: int = 15000,\n    max_source_documents: int = 20,\n    split_ratio: Tuple[float, float, float] = (0.7, 0.15, 0.15),\n    cache_dir: str = None\n) -> Dict[str, List[Dict[str, Any]]]:\n    \"\"\"\n    Загружает ограниченный поднабор Docmatix и сохраняет ТОЛЬКО документы с ОДНОЙ картинкой.\n    Каждая запись включает:\n      {\n        \"image\": PIL.Image.Image,  # <-- ОДНА картинка (не список!)\n        \"question\": str,\n        \"answer\": str,             # <-- переименовано из answers\n        \"source\": \"Docmatix\"\n      }\n    \"\"\"\n    load_kwargs = {\"cache_dir\": cache_dir} if cache_dir else {}\n\n    ds = load_dataset(\n        \"HuggingFaceM4/Docmatix\",\n        \"images\",\n        split=\"train\",\n        streaming=True,\n        **load_kwargs\n    )\n\n    entries = []\n    doc_count = 0\n    single_image_doc_count = 0 \n\n    for item in ds:\n        if doc_count >= max_source_documents or len(entries) >= max_final_samples:\n            break\n\n        raw_images = item.get(\"images\", [])\n        texts = item.get(\"texts\", [])\n\n        if not raw_images or len(raw_images) != 1 or not texts:\n            continue\n\n        image = _to_pil_image(raw_images[0])\n        if not image:\n            continue\n\n        doc_count += 1\n        single_image_doc_count += 1\n\n        for qa in texts:\n            if len(entries) >= max_final_samples:\n                break\n\n            question = qa.get(\"user\", \"\").strip()\n            answer = qa.get(\"assistant\", \"\").strip()\n            if not question or not answer:\n                continue\n\n            entries.append({\n                \"image\": image,      \n                \"question\": question,\n                \"answer\": answer,     \n                \"source\": \"Docmatix\",\n            })\n\n    print(f\" Загружено {len(entries)} примеров из {single_image_doc_count} документов Docmatix с одной картинкой.\")\n    return _split_dataset(entries, split_ratio)\n\ndef load_ruclevr(split_ratio: Tuple[float, float, float] = (0.7, 0.15, 0.15),\n                 cache_dir: str = None) -> Dict[str, List[Dict[str, Any]]]:\n    load_kwargs = {\"cache_dir\": cache_dir} if cache_dir else {}\n    ds_dict = load_dataset(\"MERA-evaluation/ruCLEVR\", **load_kwargs)\n    datasets_list = ds_dict.values() if isinstance(ds_dict, dict) else [ds_dict]\n\n    entries = []\n    for ds in datasets_list:\n        for item in ds:\n            try:\n                inputs = item.get(\"inputs\")\n                outputs = item.get(\"outputs\", \"\")\n\n                if isinstance(inputs, str):\n                    inputs = json.loads(inputs)\n                if not isinstance(inputs, dict):\n                    continue\n\n                question = inputs.get(\"question\", \"\")\n                \n                image_info = inputs.get(\"image\", {})\n                image_bytes = image_info.get(\"bytes\") if isinstance(image_info, dict) else None\n                image = _to_pil_image(image_bytes)\n\n                if not image: \n                    continue\n\n                entries.append({\n                    \"image\": image,      \n                    \"question\": question,\n                    \"answer\": str(outputs), \n                    \"source\": \"ruCLEVR\",\n                })\n            except Exception as e:\n                print(f\"Ошибка при разборе ruCLEVR item: {e}\")\n\n    return _split_dataset(entries, split_ratio)\n\ndef load_ruvqa(split_ratio: Tuple[float, float, float] = (0.7, 0.15, 0.15),\n               cache_dir: str = None) -> Dict[str, List[Dict[str, Any]]]:\n    load_kwargs = {\"cache_dir\": cache_dir} if cache_dir else {}\n    ds_dict = load_dataset(\"MERA-evaluation/ruVQA\", **load_kwargs)\n    datasets_list = ds_dict.values() if isinstance(ds_dict, dict) else [ds_dict]\n\n    entries = []\n    for ds in datasets_list:\n        for item in ds:\n            try:\n                inputs = item.get(\"inputs\")\n                outputs = item.get(\"outputs\", \"\")\n\n                if isinstance(inputs, str):\n                    inputs = json.loads(inputs)\n                if not isinstance(inputs, dict):\n                    continue\n\n                question = inputs.get(\"question\", \"\")\n\n                image_info = inputs.get(\"image\", {})\n                image_bytes = image_info.get(\"bytes\") if isinstance(image_info, dict) else None\n                image = _to_pil_image(image_bytes)\n\n                if not image:\n                    continue\n\n                entries.append({\n                    \"image\": image,     \n                    \"question\": question,\n                    \"answer\": str(outputs), \n                    \"source\": \"ruVQA\",\n                })\n            except Exception as e:\n                print(f\"Ошибка при разборе ruVQA item: {e}\")\n\n    return _split_dataset(entries, split_ratio)\n\n\ndef load_mmbench_ru(\n    split_ratio: Tuple[float, float, float] = (0.7, 0.15, 0.15),\n    cache_dir: str = None\n) -> Dict[str, List[Dict[str, Any]]]:\n    load_kwargs = {\"cache_dir\": cache_dir} if cache_dir else {}\n    ds_dict = load_dataset(\"deepvk/MMBench-ru\", **load_kwargs)\n    datasets_list = ds_dict.values() if isinstance(ds_dict, dict) else [ds_dict]\n\n    entries = []\n    for ds in datasets_list:\n        for item in ds:\n            try:\n                question = item.get(\"question\", \"\").strip()\n                hint = item.get(\"hint\", None)\n                if hint and pd.notna(hint) and str(hint).lower() != \"nan\":\n                    question = f\"{question} {hint}\".strip()\n\n                correct_letter = item.get(\"answer\", None)\n                if correct_letter not in [\"A\", \"B\", \"C\", \"D\"]:\n                    continue\n\n                options = [str(item.get(L, \"—\")).strip() for L in [\"A\", \"B\", \"C\", \"D\"]]\n                options_text = \" ; \".join(options)\n                question = f\"{question}\\nВарианты ответа: {options_text}\"\n\n                correct_text = item.get(correct_letter, None)\n                if not pd.notna(correct_text) or str(correct_text).lower() == \"nan\":\n                    continue\n                \n                raw_image = item.get(\"image\")\n                image = _to_pil_image(raw_image)\n                \n                if not image:\n                    continue\n\n                entries.append({\n                    \"image\": image,      \n                    \"question\": question,\n                    \"answer\": str(correct_text).strip(),  \n                    \"source\": \"MMBench-ru\",\n                })\n\n            except Exception as e:\n                print(f\"Ошибка при разборе MMBench-ru item: {e}\")\n\n    return _split_dataset(entries, split_ratio)\n\n\ndef load_mws_vision_bench(split_ratio: Tuple[float, float, float] = (0.7, 0.15, 0.15),\n                          cache_dir: str = None) -> Dict[str, List[Dict[str, Any]]]:\n    load_kwargs = {\"cache_dir\": cache_dir} if cache_dir else {}\n    ds_dict = load_dataset(\"MTSAIR/MWS-Vision-Bench\", **load_kwargs)\n    datasets_list = ds_dict.values() if isinstance(ds_dict, dict) else [ds_dict]\n\n    entries = []\n    for ds in datasets_list:\n        for item in ds:\n            try:\n                answers = item.get(\"answers\", [])\n                if not answers:\n                    continue\n                \n            \n                raw_image = item.get(\"image\", None)\n                image = _to_pil_image(raw_image)\n\n                if not image:\n                    continue\n\n                entries.append({\n                    \"image\": image,    \n                    \"question\": item.get(\"question\", \"\").strip(),\n                    \"answer\": str(answers), \n                    \"source\": \"MWS-Vision-Bench\",\n                })\n            except Exception as e:\n                print(f\"Ошибка при разборе MWS-Vision-Bench item: {e}\")\n\n    return _split_dataset(entries, split_ratio)","metadata":{"execution":{"iopub.status.busy":"2025-10-14T10:36:43.886859Z","iopub.execute_input":"2025-10-14T10:36:43.887094Z","iopub.status.idle":"2025-10-14T10:36:49.194268Z","shell.execute_reply.started":"2025-10-14T10:36:43.887073Z","shell.execute_reply":"2025-10-14T10:36:49.193160Z"},"trusted":true,"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nprint(\"Загрузка ruCLEVR...\")\nruclevr_data = load_ruclevr(split_ratio=(0.7, 0.15, 0.15))\nprint(f\"ruCLEVR: train={len(ruclevr_data['train'])}, val={len(ruclevr_data['val'])}, test={len(ruclevr_data['test'])}\")\n\nprint(\"Загрузка ruVQA...\")\nruvqa_data = load_ruvqa(split_ratio=(0.7, 0.15, 0.15))\nprint(f\"ruVQA: train={len(ruvqa_data['train'])}, val={len(ruvqa_data['val'])}, test={len(ruvqa_data['test'])}\")\n\nprint(\"Загрузка MMBench-ru...\")\nmmbench_data = load_mmbench_ru(split_ratio=(0.7, 0.15, 0.15))\nprint(f\"MMBench-ru: train={len(mmbench_data['train'])}, val={len(mmbench_data['val'])}, test={len(mmbench_data['test'])}\")\n\nprint(\"Загрузка MWS-Vision-Bench...\")\nmws_data = load_mws_vision_bench(split_ratio=(0.7, 0.15, 0.15))\nprint(f\"MWS-Vision-Bench: train={len(mws_data['train'])}, val={len(mws_data['val'])}, test={len(mws_data['test'])}\")\n\nprint(\"Загрузка Docmatix...\")\ndocmatrix_dataset = load_docmatix_limited(max_source_documents=20000, split_ratio=(0.7, 0.15, 0.15))\nprint(f\"Docmatix: train={len(docmatrix_dataset['train'])}, val={len(docmatrix_dataset['val'])}, test={len(docmatrix_dataset['test'])}\")","metadata":{"execution":{"iopub.status.busy":"2025-10-13T11:35:48.48754Z","iopub.execute_input":"2025-10-13T11:35:48.487877Z","iopub.status.idle":"2025-10-13T11:35:48.964484Z","shell.execute_reply.started":"2025-10-13T11:35:48.487851Z","shell.execute_reply":"2025-10-13T11:35:48.962259Z"},"trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"docmatrix_dataset['train'][2]","metadata":{"execution":{"iopub.status.busy":"2025-10-13T11:35:48.965113Z","iopub.status.idle":"2025-10-13T11:35:48.965416Z","shell.execute_reply.started":"2025-10-13T11:35:48.965282Z","shell.execute_reply":"2025-10-13T11:35:48.965295Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mws_data['train'][1]","metadata":{"execution":{"iopub.status.busy":"2025-10-13T11:35:48.96708Z","iopub.status.idle":"2025-10-13T11:35:48.967381Z","shell.execute_reply.started":"2025-10-13T11:35:48.967254Z","shell.execute_reply":"2025-10-13T11:35:48.967266Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ruclevr_data['train'][0]\n","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-10-13T11:35:48.968554Z","iopub.status.idle":"2025-10-13T11:35:48.968944Z","shell.execute_reply.started":"2025-10-13T11:35:48.968792Z","shell.execute_reply":"2025-10-13T11:35:48.968808Z"},"trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ruvqa_data['train'][0]\n","metadata":{"execution":{"iopub.status.busy":"2025-10-13T11:35:48.970461Z","iopub.status.idle":"2025-10-13T11:35:48.970838Z","shell.execute_reply.started":"2025-10-13T11:35:48.97062Z","shell.execute_reply":"2025-10-13T11:35:48.970632Z"},"trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mmbench_data['train'][1]","metadata":{"execution":{"iopub.status.busy":"2025-10-13T11:35:48.971653Z","iopub.status.idle":"2025-10-13T11:35:48.971989Z","shell.execute_reply.started":"2025-10-13T11:35:48.971854Z","shell.execute_reply":"2025-10-13T11:35:48.971868Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nimport base64\nfrom pathlib import Path\nfrom PIL import Image\nfrom io import BytesIO\nfrom tqdm import tqdm\n\nimport pandas as pd\nimport pyarrow as pa\nimport pyarrow.parquet as pq\nfrom typing import Dict, List, Any\nfrom datasets import Features, Image as HFImage, Value, Sequence\n\ndef serialize_image_for_hf(image: Image.Image) -> Dict[str, bytes]:\n    \"\"\"\n    Сериализует ОДИН объект PIL.Image в формат для datasets.Image()\n    \"\"\"\n    if not isinstance(image, Image.Image):\n        return {\"bytes\": b\"\"}\n        \n    try:\n        buffered = BytesIO()\n        image.save(buffered, format=\"PNG\")\n        return {\"bytes\": buffered.getvalue()}\n    except Exception as e:\n        print(f\"Не удалось сериализовать изображение: {e}\")\n        return {\"bytes\": b\"\"}\n\n\ndef save_to_partitioned_parquet_with_hf_metadata(\n    datasets: Dict[str, Dict[str, List[Dict]]],\n    output_dir: str = \"combined_data_parquet_simple\",\n    chunk_size: int = 100\n):\n    root_path = Path(output_dir)\n    root_path.mkdir(parents=True, exist_ok=True)\n    print(f\" Данные будут сохранены в: {root_path.absolute()}\")\n\n    features = Features({\n        'image': HFImage(decode=True), \n        'question': Value('string'),\n        'answer': Value('string'),     \n        'source': Value('string')\n    })\n\n    for ds_name, dataset_splits in tqdm(datasets.items(), desc=\"Датасеты\", unit=\"датасет\"):\n        print(f\"\\n Обработка датасета: {ds_name}\")\n\n        for split_name, records in tqdm(dataset_splits.items(), desc=f\"{ds_name} сплиты\", unit=\"сплит\", leave=False):\n            if not records:\n                print(f\"  - Пропуск пустого сплита: {split_name}\")\n                continue\n\n            print(f\"  - Подготовка сплита '{split_name}' ({len(records)} записей)\")\n\n            split_output_path = root_path / split_name\n\n            # Разбиваем на чанки\n            for chunk_start in range(0, len(records), chunk_size):\n                chunk_end = min(chunk_start + chunk_size, len(records))\n                chunk_records = records[chunk_start:chunk_end]\n\n                prepared_data = []\n                for item in chunk_records:\n                    prepared_data.append({\n                        \"image\": serialize_image_for_hf(item.get(\"image\")),\n                        \"question\": item.get(\"question\", \"\").strip(),\n                        \"answer\": item.get(\"answer\", \"\").strip(),\n                        \"source\": item.get(\"source\", ds_name),\n                    })\n\n                if not prepared_data:\n                    continue\n\n                df = pd.DataFrame(prepared_data)\n                arrow_table = pa.Table.from_pandas(df, schema=features.arrow_schema, preserve_index=False)\n\n                # Сохраняем чанк\n                pq.write_to_dataset(\n                    arrow_table,\n                    root_path=split_output_path,\n                    partition_cols=['source'],\n                    schema=features.arrow_schema,\n                    existing_data_behavior='overwrite_or_ignore'\n                )\n\n            print(f\"  Сплит '{split_name}' из '{ds_name}' успешно сохранен.\")\n\n    print(f\"\\n Все датасеты успешно сохранены!\")","metadata":{"execution":{"iopub.status.busy":"2025-10-13T11:40:29.610086Z","iopub.execute_input":"2025-10-13T11:40:29.610409Z","iopub.status.idle":"2025-10-13T11:40:29.627513Z","shell.execute_reply.started":"2025-10-13T11:40:29.610387Z","shell.execute_reply":"2025-10-13T11:40:29.626324Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Собираем датасеты в словарь (ключ — имя, значение — сам датасет)\n\nall_datasets = {\n    \"ruCLEVR\": ruclevr_data,\n    \"ruVQA\": ruvqa_data, \n    \"MMBench_ru\": mmbench_data,\n    \"MWS_Vision_Bench\": mws_data,\n    \"Docmatix\": docmatrix_dataset\n}\n\n\nsave_to_partitioned_parquet_with_hf_metadata(all_datasets, output_dir=\"combined_data\")","metadata":{"execution":{"iopub.status.busy":"2025-10-13T11:40:40.247563Z","iopub.execute_input":"2025-10-13T11:40:40.247924Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nfrom pathlib import Path\n\ndef setup_kaggle_auth():\n    try:\n        from kaggle_secrets import UserSecretsClient\n        user_secrets = UserSecretsClient()\n        username = user_secrets.get_secret(\"KAGGLE_USERNAME\")\n        key = user_secrets.get_secret(\"KAGGLE_KEY\")\n    except ImportError:\n        print(\"Используем переменные окружения для Kaggle\")\n        username = os.environ.get('KAGGLE_USERNAME')\n        key = os.environ.get('KAGGLE_KEY')\n\n    if not (username and key):\n        raise ValueError(\"Не найдены учетные данные Kaggle\")\n\n    # Создаем конфиг Kaggle\n    kaggle_dir = Path.home() / '.kaggle'\n    kaggle_dir.mkdir(parents=True, exist_ok=True)\n    \n    kaggle_json = kaggle_dir / 'kaggle.json'\n    kaggle_json.write_text(json.dumps({'username': username, 'key': key}))\n    kaggle_json.chmod(0o777)\n    \n    print(\"Аутентификация Kaggle настроена. Файл kaggle.json успешно создан и настроен.\")\n    return username\n\ndef create_dataset_metadata(username: str):\n    data_dir = Path(\"/kaggle/working/combined_data\")\n    \n    metadata = {\n        \"title\": \"DocVQA-ru-eng-v1\",\n        \"id\": f\"{username}/docvqa-ru-eng-v1\",\n        \"licenses\": [{\"name\": \"MIT\"}]\n    }\n    \n    metadata_path = data_dir / \"dataset-metadata.json\"\n    metadata_path.write_text(json.dumps(metadata, ensure_ascii=False, indent=2))\n    \n    print(\"Файл метаданных создан/проверен.\")\n    return data_dir\n\ndef upload_to_kaggle(data_dir: Path):\n    print(\"Загрузка датасета на Kaggle...\")\n    \n    result = os.system(f'kaggle datasets create -p \"{data_dir}\" --dir-mode zip --public')\n    \n    if result == 0:\n        print(\"Датасет успешно загружен!\")\n    else:\n        print(\"Ошибка при загрузке датасета\")\n\ndef main():\n    print(\"Начало загрузки датасета на Kaggle...\")\n    \n    username = setup_kaggle_auth()\n    data_dir = create_dataset_metadata(username)\n    upload_to_kaggle(data_dir)\n    \n    print(f\"\\nСсылка на датасет: https://www.kaggle.com/datasets/{username}/docvqa-ru-eng-v1\")\n    print(\"Обработка может занять несколько минут.\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}